\documentclass[12pt]{report}

\usepackage[utf8]{inputenc}
\usepackage{t1enc}
\usepackage[magyar]{babel}
\usepackage{amsmath}

\title{Structure from Motion from Two Views}
\date{}

\begin{document}
    \maketitle

    \chapter{Algoritmus}
    A Structure from motion (SfM) folyamat segítségével 3D rekonstrukciót hajthatunk végre egy képpár segítségével.

    \begin{enumerate}
        \item Két kép közötti ritka ponthalmazok megfeleltetése (pontmegfeleltetés): az első kép sarkainak azonosítása a \textit{detectMinEigenFeatures} függvénnyel, majd azok követése a második képre a \textit{vision.PointTracker} segítségével.
        \item Az esszenciális mátrix becslése \textit{estimateEssentialMatrix} használatával.
        \item Kamera elmozdulásának kiszámítása \textit{estrelpose} függvénnyel.
        \item Két kép közötti sűrű ponthalmazok megfeleltetése (pontmegfeleltetés): több pont kinyeréséhez újra kell detektálni a pontokat a \textit{detectMinEigenFeatures} függvény segítségével a \textit{'MinQuality'} opciót használva. Ezt követi a sűrű ponthalmaz követése a második képre a \textit{vision.PointTracker} használatával.
        \item Az illeszkedő pontok 3D helyzeteinek meghatározása a \textit{triangulate} segítségével (háromszögelés).
    \end{enumerate}    

    \chapter{Kód magyarázata}
        \section{Képpár betöltése}
            \begin{enumerate}
                \item \textit{fullfile(string1, string2, ...)} = az argumentumként kapott stringekből összeállít egy elérési útvonalat, pl.:\\\\
                    \texttt{path = fullfile('myfolder', 'mysubfolder')\\path = 'myfolder\textbackslash mysubfolder\textbackslash '}\\\\
                    \textit{toolboxdir(toolbox)} = visszaadja az argumentumként kapott toolbox abszolút elérési útvonalát.
                \item \textit{imageDatastore(path)} = létrehoz egy ImageDatastore objektumot a kapott elérési útvonallal meghatározott képekből. Az ImageDatastore objektum segítségével egy mappában található összes képet össze lehet gyűjteni egy változóba (de alapból nem lesz az összes kép egyszerre betöltve).
                \item \textit{readimage(datastore, n)} = betölti az n. képet a megadott datastore-ból.
                \item \textit{figure} = létrehoz egy új, üres ábra ablakot.
                \item \textit{imshowpair(image1, image2, 'montage')} = a meghatározott két képet egymás mellé helyezi a legutolsó ábrán.
                \item \textit{title('string')} = hozzáad egy címet a legutolsó ábrához.
            \end{enumerate}

        \section{A Camera Calibrator alkalmazás segítségével előre kiszámolt kamera paraméterek betöltése.}
            \begin{enumerate}
                    \item \textit{load(file\_name.mat)} = betölti egy korábban elmentett workspace adatait a jelenlegi workspace-be. A workspace egy ideiglenes tároló amely a MATLAB elindítása óta létrehozott változókat tárolja. Alapértelmezetten a MATLAB ablak jobb oldalán látható. A workspace-t el lehet menteni, így a benne tárolt változókat később vissza lehet tölteni a MATLAB-ba.
            \end{enumerate}

        \section{Lencse által okozott torzítás eltávolítása.}
            \begin{enumerate}
                \item \textit{undistortImage(image, intrinsics)} = a második argumentumként megadott kamera paramétereket felhasználva eltűnteti a kamera lencséje által okozott torzítást a megadott képről.\\
                      A kamera kalibrációja során kapott kamera paramétereket és a torzítási együtthatókat felhasználva kiszámítjuk a bemeneti kép minden pixelének eredeti pozícióját. Az egyes pixelek pozícióját az alábbi torzítások módosítják:
                        \begin{itemize}
                            \item \textbf{Radiális torzítás} = kiváltó oka, hogy a lencse szélén áthaladó fény jobban törik, mint a lencse közepén környezetében áthaladó fény. Ez kiszámolható:\\
                                \[x_d = x_u(1 + k_1r^2 + k_2r^4)\]
                                \[y_d = y_u(1 + k_1r^2 + k_2r^4)\]
                                (Ahol $x_u, y_u$ = torzulásmentes koordináták; $x_d, y_d$ = torzított koordináták; $k_1, k_2$ = radiális torzítási együtthatók; $r^2 = x_u^2 + y_u^2$)
                            \item \textbf{Tangenciális fordítás} = előfordul, ha a kameraszenzor és a lencse nem állnak tökéletesen párhuzamosan. Ez kiszámolható:\\
                                \[x_d = 2p_1x_uy_u + p_2(r^2+2x_u^2)\]
                                \[y_d = 2p_2x_uy_u + p_1(r^2 + 2y_u^2)\]
                                (Ahol $x_u, y_u$ = torzulásmentes koordináták; $x_d, y_d$ = torzított koordináták; $p_1, p_2$ = tangenciális torzítási együtthatók; $r^2 = x_u^2 + y_u^2$)\\\\
                    Az egyes pixelek korrigált helyének kiszámítása nem egész számú értékeket is előállít. Mivel a nem egész szám nem lehet pixel koordináta, ezért bilineáris interpolációt is végre kell hajtani. A bilineáris interpoláció során, a legközelebbi négy szomszédot felhasználva először lineáris interpolációt hajtunk végre az egyik irányba (pl. az x tengely mentén), majd pedig a másik irányba (az y tengely mentén):
                        \[out_P = I_1(1 - \Delta X)(1 - \Delta Y) + I_2 (\Delta X)(1 - \Delta Y) + I_3(1 - \Delta X)(\Delta Y) + I_4(\Delta X)(\Delta Y)\]
                        (Ahol $I_1, I_2, I_3, I_4$ = a szomszédos négy koordináta intenzitása az eredeti, torzított képen; $\Delta X, \Delta Y$ = a nem egész értékű koordinátákkal rendelkező vizsgált pixel és a vizsgált pixelhez legközelebb eső, egész értékű koordinátákkal rendelkező szomszédai közötti távolság; $out_P$ = végeredményként kapott pixel intenzitás)\\\\
                    A szomszédos pixelek efféle súlyzott átlagolásával, az interpoláció eredményeképp egy pixel intenzitás értéket kapunk, amely a legközelebbi egész érték koordinátával rendelkező pixel intenzitása lesz.\\
                    Az előállított, torzítatlan képen néhány pixel (leginkább a kép szélein) nem rendelkezik megfelelő pixel párral az eredeti, torzított képről (ezek azok a területek, ahol az eredeti képből nincs információ). Ezek a pixelek alapértelmezetten 0 értéket kapnak (feketék lesznek). 
                        \end{itemize}
                \end{enumerate}

            \section{Pontmegfeleltetés a képek között.}
                \begin{enumerate}
                    \item \textit{detectMinEigenFeatures(grayImage, MinQuality=0.1)} = a Shi és Tomasi féle minimum sajátérték algoritmust (Shi \& Tomasi, Minimum Eigenvalue Algorithm) használva keresi meg a kép sarokpontjait (a sarokpont jelen esetben olyan pixeleket jelentenek, amelyek éles változást mutatnak a környező pixelekhez képest). Szürkeárnyalatos képet vár argumentumként, ezért a képet még előtte az \textit{im2gray} függvénnyel szürkeárnyalatosra változtatjuk. A \textit{MinQuality} argumentum a detektált sarokpontok minőségét határozza meg. Az értékének [0, 1] tartományból választhatunk. Magasabb érték, jobb minőségű, viszont kevesebb sarokpontot is eredményez.
                    Pontmegfeleltetés esetén gyakran a sarokpontok detektálása a preferált módszer, ugyanis a sarokpontok általában könnyen azonosíthatók különböző nézőpontból és stabilak (azaz kisebb elmozdulás, zaj vagy torzítás hatására is megismerhetők).\\
                    A Shi és Tomasi féle sajátérték algoritmus a Harris sarokpont detektáló algoritmuson alapszik. A Harris sarokpont detektáló algoritmus esetén első lépésben meghatározunk egy csúszóablakot a vizsgált képen. Ha azt tapasztaljuk, hogy ezt az ablakot bármelyik irányba is mozgassuk el, nagy lesz a különbség az ablak erdeti pozíciója alatti terület és az elmozdított ablak új pozíciója alatti terület között, akkor sikeresen detektáltunk egy sarokpontot. Ezt a változást az alábbi képlet szerint mérjük:
                    \[E(u,v) = \sum_{x,y}w(x,y)[I(x+u,y+v) - I(x,y)]^2\]
                    Ahol:\\ 
                    \begin{itemize}
                        \item \textit{E} = a négyzetkülönbség a csúszóablak eredeti és elmozdított pozíciója között.
                        \item \textit{u} = a csúszóablak elmozdításának értéke az x tengely mentén.
                        \item \textit{v} = a csúszóablak elmozdításának értéke az y tengely mentén.
                        \item \textit{w(x,y)} = a csúszóablak az (x,y) pozíción
                        \item \textit{I} = a kép intenzitása a zárójelekben meghatározott pozíción, pl:
                            \begin{itemize}
                                \item \textit{I(x,y)} = az ablak eredeti pozíciója alatti terület intenzitása.
                                \item \textit{I(x+u,y+v)} = az elmozgatott ablak alatti terület intenzitása.
                            \end{itemize}
                    \end{itemize}
                \end{enumerate}
                A cél olyan csúszóablakokat találni, ahol ez az E érték nagy, bármelyik irányba is toljuk el az ablakot. Azaz olyan pozíció kell, ahol (a képletben) a szögletes zárójelben található kifejezés értéke nagy. Tehát a 
                \[\sum_{x,y}[I(x+u,y+v) - I(x,y)]^2\]
                részt kell maximalizálni. Ehhez először Taylor-sort alkalmazunk, amely után az alábbi egyenletet kapjuk (ezek után már csak közelítő eredményt kapunk):
                \[E(u,v) \approx \sum_{x,y}[I(x,y) + ul_x + vl_y - I(x,y)]^2\]
                A \textit{I(x,y) - I(x,y)} rész kiüti egymást, majd a elvégezzük a négyzetre emelést ($(a+b)^2 = a^2 + 2ab + b^2$):
                \[E(u,v) \approx \sum_{x,y}u^2l_x^2 + 2uvl_xl_y + v^2l_y^2\]
                Ezt mátrixá alakítjuk:
                \[E(u,v) \approx \begin{bmatrix} u & v \end{bmatrix} (\sum \begin{bmatrix} l_x^2 & l_xl_y \\ l_xl_y & l_y^2 \end{bmatrix}) \begin{bmatrix} u \\ v \end{bmatrix}\]
                A mátrixot (talán második momentum mátrixnak hívják) \textit{M} betűvel fogjuk jelezni és a \textit{w(x,y)} is csodával határos módon visszakerült:
                \[M = \sum w(x,y)\begin{bmatrix} l_x^2 & l_xl_y \\ l_xl_y & l_y^2 \end{bmatrix}\]
                Az \textit{M}-et behelyettesítve:
                \[E(u,v) \approx \begin{bmatrix} u & v \end{bmatrix} M \begin{bmatrix} u \\ v \end{bmatrix}\]
                To be continued...\\
                \texttt{https://docs.opencv.org/3.4/dc/d0d/tutorial\_py\_features\_harris.html}\\
                \texttt{https://aishack.in/tutorials/harris-corner-detector/}
    \chapter{Forrás}
        \begin{itemize}
            \item https://www.mathworks.com/help/vision/ug/structure-from-motion-from-two-views.html
            \item https://www.mathworks.com/help/vision/ref/undistortimage.html?s\textunderscore tid=doc\textunderscore ta
            \item https://www.mathworks.com/help/visionhdl/ug/image-undistort.html
            \item https://e-learning.ujs.sk/pluginfile.php/23441/mod\textunderscore resource/content/1/01-ProjektivKamera.pdf
            \item https://www.mathworks.com/help/vision/ref/detectmineigenfeatures.html
            \item https://aishack.in/tutorials/features/
            \item https://aishack.in/tutorials/harris-corner-detector/
            \item https://aishack.in/tutorials/shitomasi-corner-detector/
            \item https://docs.opencv.org/3.4/dc/d0d/tutorial\textunderscore py\textunderscore features\textunderscore harris.html
        \end{itemize}
\end{document}
